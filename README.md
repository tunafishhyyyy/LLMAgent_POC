# ü§ñ LLM Agent POC - Browser-Based Multi-Tool Reasoning Agent

A sophisticated browser-based LLM agent that demonstrates advanced multi-tool reasoning with real API integrations, built entirely in vanilla JavaScript for maximum hackability and educational value.

## üéØ Live Demo

**üåê Hosted Version:** http://84.247.184.189:8080

Try it out with real APIs or explore the enhanced simulation mode!

## ‚ú® Key Features

### üîß **Three Powerful Tools**
- **üîç Google Search API** - Real-time web search with formatted results
- **ü§ñ AI Pipe Workflows** - Multiple AI processing pipelines (summarize, analyze, transform, etc.)
- **üíª JavaScript Execution** - Secure code execution with sandboxed environment

### üéõÔ∏è **Multi-Provider LLM Support**
- **AI Pipe** - Single API key for multiple LLM providers (Recommended)
- **OpenAI** - Direct GPT-3.5-turbo and GPT-4 access
- **Anthropic** - Claude 3 integration (via AI Pipe)
- **Google** - Gemini Pro support (via AI Pipe)

### üé® **Professional UI/UX**
- **Bootstrap 5** responsive design
- **Real-time status** indicators and processing feedback
- **Beautiful result formatting** with syntax highlighting
- **Conversation management** with clear/save functionality
- **API key management** with browser storage

### üõ°Ô∏è **Production-Ready Features**
- **Infinite loop protection** with iteration limits
- **Comprehensive error handling** with graceful fallbacks
- **Enhanced simulation mode** when APIs aren't available
- **CORS handling** and network error recovery
- **Message validation** for proper conversation flow

## üöÄ Quick Start

### Option 1: Use Hosted Version
1. Visit http://84.247.184.189:8080
2. Add your API keys (AI Pipe recommended)
3. Start chatting with the agent!

### Option 2: Local Setup
1. **Clone the repository**
   ```bash
   git clone https://github.com/tunafishhyyyy/LLMAgent_POC.git
   cd LLMAgent_POC
   ```

2. **Start a local server**
   ```bash
   python3 -m http.server 8080
   ```

3. **Open in browser**
   ```
   http://localhost:8080
   ```

## üîë API Configuration

### üåü **AI Pipe (Recommended)**
- **What:** Single API key for multiple LLM providers
- **Get key:** https://aipipe.org/
- **Supports:** OpenAI, Anthropic, Google models through one API
- **Benefits:** Simplified setup, routing, and billing

### üîç **Google Search API**
- **Google API Key:** Get from Google Cloud Console
- **Search Engine ID:** Create a Custom Search Engine at https://cse.google.com/
- **Benefits:** Real-time web search with rich results

### ü§ñ **Direct Provider APIs**
- **OpenAI:** Get API key from https://platform.openai.com/
- **Anthropic:** Get API key from https://console.anthropic.com/
- **Google:** Get API key from Google AI Studio

## üí° Usage Examples

### üìö **Interview Practice**
```
"Interview me on JavaScript"
‚Üí Conducts structured technical interview with follow-up questions
```

### üîç **Web Research**
```
"Search for latest React trends"
‚Üí Executes Google search and presents beautifully formatted results
```

### üíª **Code Execution**
```
"Run this code: console.log('Hello World')"
‚Üí Executes JavaScript safely and shows output
```

### ü§ñ **AI Processing**
```
"Analyze this text: [your content]"
‚Üí Uses AI Pipe workflows for content analysis
```

## üèóÔ∏è Architecture

### **Core Components**

```
üìÅ LLMAgent_POC/
‚îú‚îÄ‚îÄ üìÑ index.html          # Main UI with Bootstrap styling
‚îú‚îÄ‚îÄ üß† agent.js            # Core agent logic and conversation loop
‚îú‚îÄ‚îÄ üõ†Ô∏è tools.js            # Tool implementations and execution
‚îú‚îÄ‚îÄ üé® style.css           # Custom styling and responsive design
‚îú‚îÄ‚îÄ üìö README.md           # This documentation
‚îú‚îÄ‚îÄ üîß SETUP_GUIDE.md      # Detailed setup instructions
‚îî‚îÄ‚îÄ üêõ TROUBLESHOOTING.md  # Common issues and solutions
```

### **Agent Loop Logic**

The agent implements a sophisticated reasoning loop:

```javascript
async loop() {
    while (messages.length > 0 && isProcessing) {
        // 1. Call LLM with conversation history and available tools
        const { output, toolCalls } = await callLLM(messages, tools);
        
        // 2. Display LLM response
        if (output) addMessage('agent', output);
        
        // 3. Execute any tool calls
        if (toolCalls?.length > 0) {
            const results = await executeTools(toolCalls);
            messages.push(...results);
            continue; // Loop continues with tool results
        } else {
            break; // Wait for next user input
        }
    }
}
```

### **Message Flow & Validation**

- **Message Cleaning:** Validates conversation flow for API compatibility
- **Tool Result Processing:** Formats results for both display and LLM consumption
- **Loop Protection:** Prevents infinite loops with iteration limits
- **State Management:** Proper processing state with graceful error recovery

## üîß Advanced Features

### **Enhanced Simulation Mode**
When APIs aren't available, the agent provides intelligent simulation:
- **Contextual responses** based on conversation history
- **Tool-appropriate behavior** mimicking real API responses
- **Educational value** for understanding agent capabilities

### **Professional Error Handling**
- **Network timeouts** with retry logic
- **API quota management** with informative messages
- **User-friendly errors** with actionable solutions
- **Graceful degradation** to simulation mode

### **Security & Safety**
- **Sandboxed JavaScript execution** with controlled environment
- **Input validation** and sanitization
- **API key protection** with secure storage
- **CORS handling** for cross-origin requests

## üé® UI/UX Highlights

### **Conversation Interface**
- **Message types:** User, Agent, Tool Calls, Tool Results with distinct styling
- **Real-time status:** Processing indicators and progress feedback
- **Responsive design:** Works on desktop, tablet, and mobile
- **Conversation management:** Clear, save, and load conversation history

### **Result Formatting**
- **Search results:** Clean, clickable format with metadata
- **Code execution:** Syntax highlighting with success/error indicators
- **AI workflows:** Professional result presentation
- **Tool calls:** Clear display of function calls and parameters

## üî¨ Technical Implementation

### **Multi-Provider LLM Integration**
```javascript
switch (provider) {
    case 'aipipe':
        // AI Pipe OpenRouter proxy
        apiUrl = 'https://aipipe.org/openrouter/v1/chat/completions';
        break;
    case 'openai':
        // Direct OpenAI API
        apiUrl = 'https://api.openai.com/v1/chat/completions';
        break;
    // Additional providers...
}
```

### **Tool System**
- **OpenAI-compatible function calling** interface
- **Parallel tool execution** for improved performance
- **Result aggregation** and conversation integration
- **Extensible architecture** for adding new tools

### **State Management**
- **Browser storage** for API keys and preferences
- **Conversation history** with proper message flow
- **Processing state** with loop protection
- **Error recovery** with automatic fallbacks

## üöÄ Extending the Agent

### **Adding New Tools**

1. **Define Tool Schema** in `tools.js`:
```javascript
{
    type: "function",
    function: {
        name: "my_new_tool",
        description: "What this tool does",
        parameters: {
            type: "object",
            properties: {
                input: { type: "string", description: "Input description" }
            },
            required: ["input"]
        }
    }
}
```

2. **Implement Tool Logic**:
```javascript
async executeMyNewTool(params) {
    try {
        // Tool implementation
        return { success: true, result: "output" };
    } catch (error) {
        return { success: false, error: error.message };
    }
}
```

### **Adding New LLM Providers**

1. **Add provider case** in `callLLM()` method
2. **Implement API request** formatting
3. **Handle response** parsing
4. **Add UI configuration** options

## üìä Project Evaluation

### **Functionality** ‚úÖ
- ‚úÖ Google Search API integration with real results
- ‚úÖ AI Pipe workflows with multiple processing types
- ‚úÖ JavaScript execution with secure sandboxing
- ‚úÖ Multi-provider LLM support with routing
- ‚úÖ Robust conversation management

### **Code Quality** ‚úÖ
- ‚úÖ Modular architecture with separated concerns
- ‚úÖ Comprehensive error handling and validation
- ‚úÖ Clean, documented code with consistent style
- ‚úÖ Extensible design for future enhancements
- ‚úÖ Production-ready features and safeguards

### **UI/UX Polish** ‚úÖ
- ‚úÖ Professional Bootstrap-based design
- ‚úÖ Responsive layout for all devices
- ‚úÖ Beautiful result formatting and syntax highlighting
- ‚úÖ Real-time feedback and status indicators
- ‚úÖ Intuitive conversation management

## üõ†Ô∏è Development & Deployment

### **Local Development**
```bash
# Start development server
python3 -m http.server 8080

# Or use any static file server
npx serve .
```

### **Production Deployment**
- **Static hosting** on any web server
- **No backend required** - pure client-side application
- **HTTPS recommended** for API security
- **CDN friendly** for global distribution

## ü§ù Contributing

This project demonstrates modern LLM agent architecture and is perfect for:
- **Learning** agent development patterns
- **Teaching** multi-tool reasoning concepts
- **Prototyping** new agent capabilities
- **Research** into browser-based AI applications

## üìú License

Open source - feel free to use for educational and commercial purposes.

## üîó Links

- **Live Demo:** http://84.247.184.189:8080
- **Repository:** https://github.com/tunafishhyyyy/LLMAgent_POC
- **AI Pipe:** https://aipipe.org/
- **OpenAI API:** https://platform.openai.com/
- **Google Custom Search:** https://developers.google.com/custom-search

---

**Built with ‚ù§Ô∏è for the LLM agent community**
